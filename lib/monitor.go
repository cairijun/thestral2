package lib

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"runtime"
	"sort"
	"sync"
	"sync/atomic"
	"time"
)

// monitorUpdateInterval is the interval at which the monitor update its
// internal state. This is a variable only for testing and should be considered
// as a constant in other cases.
var monitorUpdateInterval = time.Second * 1

const connLatencyEmaAlpha = 0.8

// AppMonitor records and reports runtime statistics of an thestral app.
type AppMonitor struct {
	transferMeter    transferMeter
	tunnelMonitors   sync.Map // ReqID (string) -> *TunnelMonitor
	upstreamMonitors sync.Map // upstream (string) -> *UpstreamMonitor
}

// AppMonitorReport is the statistics report generated by AppMonitor.
type AppMonitorReport struct {
	// service information
	ThestralVersion string
	Runtime         string
	// global transfer statistics
	AvgConnLatencyMs float32
	ErrorCount       uint32
	UploadSpeed      float32
	DownloadSpeed    float32
	BytesUploaded    uint64
	BytesDownloaded  uint64
	// per-tunnel report
	Tunnels []*TunnelMonitorReport
	// per-upstream report
	Upstreams []*UpstreamMonitorReport
}

// Start the AppMonitor.
func (m *AppMonitor) Start(path string) {
	go func() {
		tickCh := time.Tick(monitorUpdateInterval)
		for {
			<-tickCh
			m.updateEpoch()
		}
	}()

	if len(path) == 0 {
		path = "/"
	} else {
		if path[0] != '/' {
			path = "/" + path
		}
		if path[len(path)-1] != '/' {
			path += "/"
		}
	}
	m.registerRPCHandlers(path)
}

func (m *AppMonitor) registerRPCHandlers(path string) {
	// full report
	http.HandleFunc("/debug/monitor"+path,
		func(w http.ResponseWriter, r *http.Request) {
			if reportJSONBytes, err :=
				json.MarshalIndent(m.Report(), "", "  "); err != nil {
				w.WriteHeader(http.StatusInternalServerError)
				_, _ = w.Write([]byte(fmt.Sprintf(
					"Failed to generate monitor report: %s", err.Error())))
			} else {
				w.Header().Set("Content-Type", "text/json; charset=utf-8")
				_, _ = w.Write(reportJSONBytes)
			}
		})
	// single tunnel
	// HTTP DELETE: kill the tunnel
	// Other methods: report the tunnel report
	tunnelMonitorBaseURI := "/debug/monitor" + path + "tunnel/"
	tunnelMonitorBaseURILen := len(tunnelMonitorBaseURI)
	http.HandleFunc(tunnelMonitorBaseURI,
		func(w http.ResponseWriter, r *http.Request) {
			if len(r.URL.Path) <= tunnelMonitorBaseURILen {
				w.WriteHeader(http.StatusNotFound)
				return
			}
			reqID := r.URL.Path[tunnelMonitorBaseURILen:]
			if tunnel := m.getTunnelMonitor(reqID); tunnel == nil {
				w.WriteHeader(http.StatusNotFound)
				_, _ = w.Write(
					[]byte(fmt.Sprintf("Tunnel %s not found", reqID)))
			} else if r.Method == http.MethodDelete {
				tunnel.ForceKillTunnel()
			} else if reportJSONBytes, err :=
				json.MarshalIndent(tunnel.Report(), "", "  "); err != nil {
				w.WriteHeader(http.StatusInternalServerError)
				_, _ = w.Write([]byte(fmt.Sprintf(
					"Failed to generate monitor report: %s", err.Error())))
			} else {
				w.Header().Set("Content-Type", "text/json; charset=utf-8")
				_, _ = w.Write(reportJSONBytes)
			}
		})
}

func (m *AppMonitor) getUpstreamMonitor(upstream string) (um *UpstreamMonitor) {
	if value, ok := m.upstreamMonitors.Load(upstream); ok {
		um = value.(*UpstreamMonitor)
	} else {
		value, _ := m.upstreamMonitors.LoadOrStore(
			upstream, &UpstreamMonitor{name: upstream})
		um = value.(*UpstreamMonitor)
	}
	return
}

// OpenTunnelMonitor creates a tunnel monitor. The TunnelMonitor must be Closed
// when the tunnel ends.
func (m *AppMonitor) OpenTunnelMonitor(
	req ProxyRequest, rule string, downstream string,
	upstream string, serverIDs []*PeerIdentifier, boundAddr string,
	connLatency time.Duration, cancelFunc context.CancelFunc) *TunnelMonitor {
	um := m.getUpstreamMonitor(upstream)
	tm := newTunnelMonitor(
		m, um, req, rule, downstream, upstream, serverIDs, boundAddr, cancelFunc)
	tm.transferMeter.AddConnLatency(connLatency)
	um.transferMeter.AddConnLatency(connLatency)
	m.transferMeter.AddConnLatency(connLatency)
	m.tunnelMonitors.Store(req.ID(), tm)
	return tm
}

// AddError increases the error count of the monitor.
func (m *AppMonitor) AddError(upstream string) {
	m.getUpstreamMonitor(upstream).transferMeter.AddError()
	m.transferMeter.AddError()
}

func (m *AppMonitor) updateEpoch() {
	m.transferMeter.PushHistory()
	m.tunnelMonitors.Range(func(key interface{}, value interface{}) bool {
		value.(*TunnelMonitor).updateEpoch()
		return true
	})
	m.upstreamMonitors.Range(func(key interface{}, value interface{}) bool {
		value.(*UpstreamMonitor).updateEpoch()
		return true
	})
}

// Report generates a AppMonitorReport.
func (m *AppMonitor) Report() (report AppMonitorReport) {
	report.ThestralVersion = ThestralVersion
	report.Runtime = fmt.Sprintf("%s on %s/%s",
		runtime.Version(), runtime.GOOS, runtime.GOARCH)

	report.AvgConnLatencyMs = m.transferMeter.emaConnLatencyMs
	report.ErrorCount = m.transferMeter.errorCount
	report.UploadSpeed, report.DownloadSpeed = m.transferMeter.Speed()
	report.BytesUploaded, report.BytesDownloaded =
		m.transferMeter.BytesTransferred()

	m.tunnelMonitors.Range(func(key interface{}, value interface{}) bool {
		tunnelReport := value.(*TunnelMonitor).Report()
		report.Tunnels = append(report.Tunnels, &tunnelReport)
		return true
	})
	sort.Slice(report.Tunnels, func(i, j int) bool {
		return report.Tunnels[i].EstablishedSince.After(
			report.Tunnels[j].EstablishedSince)
	})

	m.upstreamMonitors.Range(func(key interface{}, value interface{}) bool {
		upReport := value.(*UpstreamMonitor).Report()
		report.Upstreams = append(report.Upstreams, &upReport)
		return true
	})
	sort.Slice(report.Upstreams, func(i, j int) bool {
		return report.Upstreams[i].Name < report.Upstreams[j].Name
	})
	return
}

func (m *AppMonitor) getTunnelMonitor(requestID string) *TunnelMonitor {
	if value, ok := m.tunnelMonitors.Load(requestID); ok {
		return value.(*TunnelMonitor)
	}
	return nil
}

// TunnelMonitor records statistics of a proxy tunnel.
type TunnelMonitor struct {
	appMonitor       *AppMonitor
	upstreamMonitor  *UpstreamMonitor
	request          ProxyRequest
	rule             string
	downstream       string
	upstream         string
	serverIDs        []*PeerIdentifier
	boundAddr        string
	establishedSince time.Time
	transferMeter    transferMeter
	cancelFunc       context.CancelFunc
}

// TunnelMonitorReport is the report generated by TunnelMonitor.
type TunnelMonitorReport struct {
	// basic
	RequestID        string
	Rule             string
	EstablishedSince time.Time
	ElapsedTimeSecs  float64
	// downstream info
	Downstream string
	ClientIDs  []*PeerIdentifier
	ClientAddr string
	TargetAddr string
	// upstream info
	Upstream  string
	ServerIDs []*PeerIdentifier
	BoundAddr string
	// statistics
	ConnLatencyMs   float32
	UploadSpeed     float32
	DownloadSpeed   float32
	BytesUploaded   uint64
	BytesDownloaded uint64
}

func newTunnelMonitor(
	appMonitor *AppMonitor, upstreamMonitor *UpstreamMonitor, req ProxyRequest,
	rule string, downstream string, upstream string,
	serverIDs []*PeerIdentifier, boundAddr string,
	cancelFunc context.CancelFunc) *TunnelMonitor {
	return &TunnelMonitor{
		appMonitor:       appMonitor,
		upstreamMonitor:  upstreamMonitor,
		request:          req,
		rule:             rule,
		downstream:       downstream,
		upstream:         upstream,
		serverIDs:        serverIDs,
		boundAddr:        boundAddr,
		establishedSince: time.Now(),
		cancelFunc:       cancelFunc,
	}
}

func (m *TunnelMonitor) updateEpoch() {
	m.transferMeter.PushHistory()
}

// IncBytesUploaded records the number of bytes in a trunk uploaded.
func (m *TunnelMonitor) IncBytesUploaded(n uint32) {
	m.appMonitor.transferMeter.IncUploaded(n)
	m.upstreamMonitor.transferMeter.IncUploaded(n)
	m.transferMeter.IncUploaded(n)
}

// IncBytesDownloaded records the number of bytes in a trunk downloaded.
func (m *TunnelMonitor) IncBytesDownloaded(n uint32) {
	m.appMonitor.transferMeter.IncDownloaded(n)
	m.upstreamMonitor.transferMeter.IncDownloaded(n)
	m.transferMeter.IncDownloaded(n)
}

// ForceKillTunnel forcely kill the tunnel.
func (m *TunnelMonitor) ForceKillTunnel() {
	m.cancelFunc()
}

// Close the tunnel monitor. This must be called at the end of the tunnel.
func (m *TunnelMonitor) Close() {
	m.appMonitor.tunnelMonitors.Delete(m.request.ID())
}

// Report the statistics of the tunnel.
func (m *TunnelMonitor) Report() (report TunnelMonitorReport) {
	report.RequestID = m.request.ID()
	report.Rule = m.rule
	report.EstablishedSince = m.establishedSince
	report.ElapsedTimeSecs = time.Since(m.establishedSince).Seconds()
	report.Downstream = m.downstream
	report.ClientIDs, _ = m.request.GetPeerIdentifiers()
	report.ClientAddr = m.request.PeerAddr()
	report.TargetAddr = m.request.TargetAddr().String()
	report.Upstream = m.upstream
	report.ServerIDs = m.serverIDs
	report.BoundAddr = m.boundAddr
	report.ConnLatencyMs = m.transferMeter.emaConnLatencyMs
	report.UploadSpeed, report.DownloadSpeed = m.transferMeter.Speed()
	report.BytesUploaded, report.BytesDownloaded =
		m.transferMeter.BytesTransferred()
	return
}

// Format generates a human-readable report. The format verb must be '%v'.
func (r TunnelMonitorReport) Format(f fmt.State, c rune) {
	if c != 'v' {
		panic("Unknown verb for TunnelMonitorReport: " + string(c))
	}
	_, _ = fmt.Fprintf(f, "RequestID: %s\n", r.RequestID)
	_, _ = fmt.Fprintf(f, "Rule: %s\n", r.Rule)
	_, _ = fmt.Fprintf(f, "EstablishedSince: %s\n",
		r.EstablishedSince.Local().Format(time.RFC1123))
	elspsed := time.Duration(int64(r.ElapsedTimeSecs) * int64(time.Second))
	_, _ = fmt.Fprintf(f, "ElapsedTime: %s\n", elspsed.String())
	_, _ = fmt.Fprintf(f, "Downstream: %s\n", r.Downstream)
	_, _ = fmt.Fprintf(f, "ClientIDs:\n")
	for _, id := range r.ClientIDs {
		printPeerID(f, "  ", id)
	}
	_, _ = fmt.Fprintf(f, "ClientAddr: %s\n", r.ClientAddr)
	_, _ = fmt.Fprintf(f, "TargetAddr: %s\n", r.TargetAddr)
	_, _ = fmt.Fprintf(f, "Upstream: %s\n", r.Upstream)
	_, _ = fmt.Fprintf(f, "ServerIDs:\n")
	for _, id := range r.ServerIDs {
		printPeerID(f, "  ", id)
	}
	_, _ = fmt.Fprintf(f, "BoundAddr: %s\n", r.BoundAddr)
	_, _ = fmt.Fprintf(f, "ConnLatency: %.2f ms\n", r.ConnLatencyMs)
	_, _ = fmt.Fprintf(f, "UploadSpeed: %s/s\n",
		BytesHumanized(uint64(r.UploadSpeed)))
	_, _ = fmt.Fprintf(f, "DownloadSpeed: %s/s\n",
		BytesHumanized(uint64(r.DownloadSpeed)))
	_, _ = fmt.Fprintf(f, "BytesUploaded: %s\n",
		BytesHumanized(r.BytesUploaded))
	_, _ = fmt.Fprintf(f, "BytesDownloaded: %s\n",
		BytesHumanized(r.BytesDownloaded))
}

// UpstreamMonitor records statistics of an upstream.
type UpstreamMonitor struct {
	name          string
	transferMeter transferMeter
}

// UpstreamMonitorReport is the report of an UpstreamMonitor.
type UpstreamMonitorReport struct {
	Name             string
	AvgConnLatencyMs float32
	ErrorCount       uint32
	UploadSpeed      float32
	DownloadSpeed    float32
	BytesUploaded    uint64
	BytesDownloaded  uint64
}

// Report generates a report for the UpstreamMonitor.
func (m *UpstreamMonitor) Report() (report UpstreamMonitorReport) {
	report.Name = m.name
	report.AvgConnLatencyMs = m.transferMeter.emaConnLatencyMs
	report.ErrorCount = m.transferMeter.errorCount
	report.UploadSpeed, report.DownloadSpeed = m.transferMeter.Speed()
	report.BytesUploaded, report.BytesDownloaded =
		m.transferMeter.BytesTransferred()
	return
}

func (m *UpstreamMonitor) updateEpoch() {
	m.transferMeter.PushHistory()
}

func printPeerID(w io.Writer, indent string, i *PeerIdentifier) {
	_, _ = fmt.Fprintf(w, "%s%s/%s\n", indent, i.Scope, i.Name)
	_, _ = fmt.Fprintf(w, "%s%sUniqueID: %s\n", indent, indent, i.UniqueID)
	for k, v := range i.ExtraInfo {
		_, _ = fmt.Fprintf(w, "%s%s%s: ", indent, indent, k)
		if s, ok := v.(fmt.Stringer); ok {
			_, _ = fmt.Fprintf(w, "%s\n", s.String())
		} else {
			_, _ = fmt.Fprintf(w, "%+v\n", v)
		}
	}
}

// transferMeter measures the speed of a bidirection transfer.
type transferMeter struct {
	bytesUploaded          uint64
	bytesDownloaded        uint64
	bytesUploadedHistory   uint64 // high, low = bytes[t - 2], bytes[t - 1]
	bytesDownloadedHistory uint64 // high, low = bytes[t - 2], bytes[t - 1]
	emaConnLatencyMs       float32
	errorCount             uint32
	// gap between the lastest two consecutive lastPushTimes
	lastPushGapNs int64
	// last time we pushed bytesXxx to bytesXxxHistory
	lastPushTime time.Time
	// This mutex is to protect some states that cannot be easily protected
	// via atomic operations. Currently it is protecting emaConnLatencyMs.
	mtx SpinMutex
}

func (m *transferMeter) IncUploaded(n uint32) {
	atomic.AddUint64(&m.bytesUploaded, uint64(n))
}

func (m *transferMeter) IncDownloaded(n uint32) {
	atomic.AddUint64(&m.bytesDownloaded, uint64(n))
}

func (m *transferMeter) AddConnLatency(connLatency time.Duration) {
	latMs := float32(connLatency.Seconds() * 1e3)
	m.mtx.Lock()
	defer m.mtx.Unlock()
	if m.emaConnLatencyMs == 0.0 {
		m.emaConnLatencyMs = latMs
	} else {
		m.emaConnLatencyMs = latMs*connLatencyEmaAlpha +
			m.emaConnLatencyMs*(1-connLatencyEmaAlpha)
	}
}

func (m *transferMeter) AddError() {
	atomic.AddUint32(&m.errorCount, 1)
}

// PushHistory records the current transferred statistics.
// It cannot be called concurrently.
func (m *transferMeter) PushHistory() {
	bytesUploaded := uint32(atomic.LoadUint64(&m.bytesUploaded))
	bytesDownloaded := uint32(atomic.LoadUint64(&m.bytesDownloaded))
	now := time.Now()
	// We should be the ONLY WRITER to the history fields,
	// so we don't need atomic loads for them here.
	upHistory := (m.bytesUploadedHistory << 32) | uint64(bytesUploaded)
	downHistory := (m.bytesDownloadedHistory << 32) | uint64(bytesDownloaded)
	atomic.StoreUint64(&m.bytesUploadedHistory, upHistory)
	atomic.StoreUint64(&m.bytesDownloadedHistory, downHistory)
	if !m.lastPushTime.IsZero() {
		atomic.StoreInt64(
			&m.lastPushGapNs, now.Sub(m.lastPushTime).Nanoseconds())
	}
	// Others SHOULD NOT ACCESS lastPushTime in any case,
	// so we don't use atomic store for it.
	m.lastPushTime = now
}

func (m *transferMeter) BytesTransferred() (up uint64, down uint64) {
	up = atomic.LoadUint64(&m.bytesUploaded)
	down = atomic.LoadUint64(&m.bytesDownloaded)
	return
}

// speed calculates the number of bytes transferred per second.
func (m *transferMeter) Speed() (uploadSpeed float32, downloadSpeed float32) {
	lastPushGapNs := atomic.LoadInt64(&m.lastPushGapNs)
	bytesUploadedHistory := atomic.LoadUint64(&m.bytesUploadedHistory)
	bytesDownloadedHistory := atomic.LoadUint64(&m.bytesDownloadedHistory)
	if lastPushGapNs == 0 {
		return 0, 0
	}
	gapSecs := float32(lastPushGapNs/1e9) + float32(lastPushGapNs%1e9)/1e9
	upBytes := uint32(bytesUploadedHistory) - uint32(bytesUploadedHistory>>32)
	downBytes := uint32(bytesDownloadedHistory) - uint32(bytesDownloadedHistory>>32)
	uploadSpeed = float32(upBytes) / gapSecs
	downloadSpeed = float32(downBytes) / gapSecs
	return
}
